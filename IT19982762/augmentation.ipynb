{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Lybs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_annotations(file_path):\n",
    "    \"\"\"Load YOLO annotations from a file.\"\"\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        annotations = []\n",
    "        for line in file:\n",
    "            data = line.strip().split()\n",
    "            label = int(data[0])  # Class label\n",
    "            bbox = list(map(float, data[1:]))  # YOLO format: [x_center, y_center, width, height]\n",
    "            annotations.append((label, bbox))\n",
    "    return annotations\n",
    "\n",
    "def save_yolo_annotations(file_path, annotations):\n",
    "    \"\"\"Save YOLO annotations to a file.\"\"\"\n",
    "    with open(file_path, \"w\") as file:\n",
    "        for label, bbox in annotations:\n",
    "            bbox_str = \" \".join(map(str, bbox))\n",
    "            file.write(f\"{label} {bbox_str}\\n\")\n",
    "\n",
    "def clip_bboxes(bboxes):\n",
    "    \"\"\"Clip bounding boxes to stay within [0, 1] range.\"\"\"\n",
    "    clipped_bboxes = []\n",
    "    for bbox in bboxes:\n",
    "        x_center, y_center, width, height = bbox\n",
    "        x_center = max(0, min(1, x_center))\n",
    "        y_center = max(0, min(1, y_center))\n",
    "        width = max(0, min(1, width))\n",
    "        height = max(0, min(1, height))\n",
    "        clipped_bboxes.append([x_center, y_center, width, height])\n",
    "    return clipped_bboxes\n",
    "\n",
    "def augment_images_and_annotations(image_folder, annotation_folder):\n",
    "\n",
    "    transformations = [\n",
    "        (A.Compose([A.HorizontalFlip(p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"horizontalflip\"),\n",
    "        (A.Compose([A.GaussianBlur(blur_limit=(3, 7), p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"gaussianblur\"),\n",
    "        (A.Compose([A.RandomBrightnessContrast(p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"brightnesscontrast\"),\n",
    "        (A.Compose([A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"huesaturationvalue\"),\n",
    "        (A.Compose([A.CoarseDropout(max_holes=8, max_height=32, max_width=32, min_holes=1, min_height=16, min_width=16, fill_value=0, p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"coarsedropout\"),\n",
    "        (A.Compose([A.Perspective(scale=(0.05, 0.1), p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"perspective\"),\n",
    "        (A.Compose([A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"elastictransform\"),\n",
    "        (A.Compose([A.RandomScale(scale_limit=0.2, p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"randomscale\")\n",
    "    ]\n",
    "\n",
    "   \n",
    "\n",
    "    # Process each image and its corresponding annotation\n",
    "    for file_name in os.listdir(image_folder):\n",
    "        if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "            # Load image\n",
    "            image_path = os.path.join(image_folder, file_name)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is None:\n",
    "                print(f\"Failed to load image {file_name}, skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Load corresponding annotation\n",
    "            base_name, ext = os.path.splitext(file_name)\n",
    "            annotation_path = os.path.join(annotation_folder, f\"{base_name}.txt\")\n",
    "            if not os.path.exists(annotation_path):\n",
    "                print(f\"Annotation file for {file_name} not found, skipping...\")\n",
    "                continue\n",
    "\n",
    "            annotations = load_yolo_annotations(annotation_path)\n",
    "            bboxes = [bbox for _, bbox in annotations]\n",
    "            class_labels = [label for label, _ in annotations]\n",
    "\n",
    "            # Apply each augmentation\n",
    "            for transform, aug_name in transformations:\n",
    "                try:\n",
    "                    augmented = transform(\n",
    "                        image=image,\n",
    "                        bboxes=bboxes,\n",
    "                        class_labels=class_labels\n",
    "                    )\n",
    "                    augmented_image = augmented[\"image\"]\n",
    "                    augmented_bboxes = augmented[\"bboxes\"]\n",
    "\n",
    "                    # Clip bounding boxes\n",
    "                    augmented_bboxes = clip_bboxes(augmented_bboxes)\n",
    "\n",
    "                    # Save augmented image\n",
    "                    new_file_name = f\"{base_name}_{aug_name}{ext}\"\n",
    "                    save_path_image = os.path.join(image_folder, new_file_name)\n",
    "                    cv2.imwrite(save_path_image, augmented_image)\n",
    "\n",
    "                    # Save augmented annotation\n",
    "                    new_annotation_file = f\"{base_name}_{aug_name}.txt\"\n",
    "                    save_path_annotation = os.path.join(annotation_folder, new_annotation_file)\n",
    "                    augmented_annotations = [\n",
    "                        (class_labels[i], augmented_bboxes[i])\n",
    "                        for i in range(len(class_labels))\n",
    "                    ]\n",
    "                    save_yolo_annotations(save_path_annotation, augmented_annotations)\n",
    "\n",
    "                    # print(f\"Saved augmented image: {new_file_name} and annotation: {new_annotation_file}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to augment {file_name} with {aug_name}: {e}\")\n",
    "\n",
    "    print(\"Data augmentation completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hashan\\anaconda3\\envs\\agm-image\\lib\\site-packages\\albumentations\\core\\composition.py:243: UserWarning: Got processor for bboxes, but no transform to process it.\n",
      "  self._set_keys()\n",
      "C:\\Users\\Hashan\\AppData\\Local\\Temp\\ipykernel_2848\\935390809.py:40: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
      "  (A.Compose([A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=1.0)], bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])), \"elastictransform\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation completed!\n"
     ]
    }
   ],
   "source": [
    "# Specify folder paths\n",
    "image_folder = \"dataset\\\\images\"\n",
    "annotation_folder = \"dataset\\\\labels\"\n",
    "\n",
    "# Run augmentation\n",
    "augment_images_and_annotations(image_folder, annotation_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displya images with their corresponding BBX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_yolo_label(label_path):\n",
    "    \"\"\"\n",
    "    Reads YOLO format label data from a text file.\n",
    "\n",
    "    Parameters:\n",
    "    - label_path: Path to the label file.\n",
    "\n",
    "    Returns:\n",
    "    - A list of tuples containing (class_id, x_center, y_center, width, height).\n",
    "    \"\"\"\n",
    "    with open(label_path, 'r') as f:\n",
    "        labels = []\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            class_id = int(parts[0])\n",
    "            x_center, y_center, width, height = map(float, parts[1:])\n",
    "            labels.append((class_id, x_center, y_center, width, height))\n",
    "        return labels\n",
    "\n",
    "def draw_bounding_boxes(image, labels, class_names):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes on an image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: The input image (numpy array).\n",
    "    - labels: A list of YOLO labels [(class_id, x_center, y_center, width, height), ...].\n",
    "    - class_names: List of class names corresponding to class IDs.\n",
    "\n",
    "    Returns:\n",
    "    - The image with bounding boxes drawn on it.\n",
    "    \"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, width, height = label\n",
    "        x1 = int((x_center - width / 2) * w)\n",
    "        y1 = int((y_center - height / 2) * h)\n",
    "        x2 = int((x_center + width / 2) * w)\n",
    "        y2 = int((y_center + height / 2) * h)\n",
    "        \n",
    "        # Draw the rectangle\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
    "        \n",
    "        # Put the class label\n",
    "        label_text = class_names[class_id] if class_id < len(class_names) else f\"Class {class_id}\"\n",
    "        cv2.putText(image, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 3)\n",
    "    return image\n",
    "\n",
    "def display_images_with_labels(image_folder, label_folder, class_names):\n",
    "    \"\"\"\n",
    "    Displays images with bounding boxes using YOLO labels.\n",
    "\n",
    "    Parameters:\n",
    "    - image_folder: Path to the folder containing images.\n",
    "    - label_folder: Path to the folder containing YOLO label files.\n",
    "    - class_names: List of class names corresponding to class IDs.\n",
    "    \"\"\"\n",
    "    image_files = sorted([f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png', 'jpeg'))])\n",
    "    \n",
    "    for image_file in image_files:\n",
    "        # Get corresponding label file\n",
    "        label_file = os.path.join(label_folder, os.path.splitext(image_file)[0] + '.txt')\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        \n",
    "        # Read image\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Read labels\n",
    "        if os.path.exists(label_file):\n",
    "            labels = read_yolo_label(label_file)\n",
    "        else:\n",
    "            labels = []\n",
    "        \n",
    "        # Draw bounding boxes\n",
    "        image_with_boxes = draw_bounding_boxes(image, labels, class_names)\n",
    "        # print(labels)\n",
    "        # Display image\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image_with_boxes)\n",
    "        plt.axis('off')\n",
    "        plt.title(image_file)\n",
    "        plt.show()\n",
    "\n",
    "# Example Usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"dataset\\\\images\"  # Replace with your image folder path\n",
    "label_folder = \"dataset\\\\labels\"  # Replace with your label folder path\n",
    "class_names = [\"bulathwita\",\"dodol\",\"hakuru\",\"kiribath\",\"pani_walalu\"]  # Replace with your class names\n",
    "\n",
    "display_images_with_labels(image_folder, label_folder, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data set in to train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(images_folder, annotations_folder, output_folder, train_ratio=0.7):\n",
    "    # Ensure output directories exist\n",
    "    train_images_folder = os.path.join(output_folder, \"train\", \"images\")\n",
    "    val_images_folder = os.path.join(output_folder, \"val\", \"images\")\n",
    "    train_annotations_folder = os.path.join(output_folder, \"train\", \"annotations\")\n",
    "    val_annotations_folder = os.path.join(output_folder, \"val\", \"annotations\")\n",
    "    \n",
    "    os.makedirs(train_images_folder, exist_ok=True)\n",
    "    os.makedirs(val_images_folder, exist_ok=True)\n",
    "    os.makedirs(train_annotations_folder, exist_ok=True)\n",
    "    os.makedirs(val_annotations_folder, exist_ok=True)\n",
    "\n",
    "    # Get a list of image files and corresponding annotation files\n",
    "    image_files = sorted([f for f in os.listdir(images_folder) if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "    annotation_files = sorted([f for f in os.listdir(annotations_folder) if f.endswith('.txt')])\n",
    "    \n",
    "    # Ensure image files have corresponding annotation files\n",
    "    paired_data = [\n",
    "        (os.path.join(images_folder, img), os.path.join(annotations_folder, img.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')))\n",
    "        for img in image_files if os.path.exists(os.path.join(annotations_folder, img.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')))\n",
    "    ]\n",
    "\n",
    "    # Split into train and validation sets\n",
    "    train_data, val_data = train_test_split(paired_data, train_size=train_ratio, random_state=42)\n",
    "    \n",
    "    # Copy files to respective folders\n",
    "    for img_path, ann_path in train_data:\n",
    "        shutil.copy(img_path, train_images_folder)\n",
    "        shutil.copy(ann_path, train_annotations_folder)\n",
    "\n",
    "    for img_path, ann_path in val_data:\n",
    "        shutil.copy(img_path, val_images_folder)\n",
    "        shutil.copy(ann_path, val_annotations_folder)\n",
    "\n",
    "    print(f\"Data successfully split into training and validation sets.\")\n",
    "    print(f\"Training set: {len(train_data)} images, Validation set: {len(val_data)} images.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully split into training and validation sets.\n",
      "Training set: 327 images, Validation set: 141 images.\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "images_folder = \"dataset\\\\images\"\n",
    "annotations_folder = \"dataset\\\\labels\"\n",
    "output_folder = \"\"\n",
    "\n",
    "split_dataset(images_folder, annotations_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agm-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
